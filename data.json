[{"permalink":"//","layout":"default","title":"starter","content":"# starter\n\n1. [Generate with the same files and folders](https://github.com/rundocs/starter/generate) from this repository\n2. Set up your GitHub Pages to source(`/`)\n3. Now you can view your documentation in your site\n\n## site.pages\n\n<!-- prettier-ignore-start -->\n\n| source | link |\n| --------------- | -------------------------------------------------------------- |\n{% for page in site.pages -%}\n| {{ page.path }} | [{{ page.url | relative_url }}]({{ page.url | relative_url }}) |\n{% endfor %}\n\n<!-- prettier-ignore-end -->\n\n## Documents\n\nhttps://jekyll-rtd-theme.rundocs.io\n\n## Local debug\n\n```sh\nmake\nmake server\n```\n\n## The license\n\nThe theme is available as open source under the terms of the MIT License\n","dir":"/","name":"README.md","path":"README.md","url":"/"},{"layout":"default","title":"關於 Star Lab","content":"# 關於 Star Lab\n\n## 背景與使命\n\n能獨立自主完成任務的無人機系統 - 無人機發展已從軍事延伸到民生用途，從環境探勘、物資運送、農業植保、安全監控到娛樂表演等，有著極大的內需市場空間。\n\n其應用對國土資訊及社會運作具有高滲透性，因此是經濟發展與國家安全的重要戰略目標，是須積極發展關鍵優勢技術的項目。\n\n![智慧無人機載具實驗室](/assets/images/all.jpg)\n\n## STAR：Smart Technology for Autonomous UAV\n\n智慧無人載具實驗室（Star \bLab）致力於自主無人機系統的研發，該系統由 **感知（Perception）、運動（Motion）、認知（Cognition）、介面（Interface）** 四大模組所組成，其應用觸及小型物件配送、建築檢視、農田災損掃描等，操作人員可透過控制面板指示無人機執行任務，節省成本也降低人為處理的風險。\n\n![四大模組](/assets/images/architecturesimple.png)\n\n## 目標與任務\n\n專注於建置「無人機自主智慧系統」，從初階的飛行控制到中階於較複雜環境中執行任務的應變飛行，以深度學習架構為基礎，透過即時環境感知，結合動態立體空間建模與路徑規劃技術，依照情境策略應變，並輔以視覺化介面監控無人機；我們的核心技術包含：​\n- 空間知識模型\n- 任務行為樹規劃\n- 影像辨識與電腦視覺\n- 影像還原與模型壓縮\n- 路徑規劃與機上運算\n- 三維定位與避障功能\n- 無人機應用相關軟體之研發\n\n![無人機掃描模型建築](/assets/images/buildinginspection.jpg)\n","dir":"/about/","name":"0_starlab.md","path":"about/0_starlab.md","url":"/about/0_starlab.html"},{"layout":"default","title":"團隊成員與合作夥伴","content":"# 團隊成員與合作夥伴\n\n## 劉吉軒\n![劉吉軒](/assets/images/jyliu.jpg)\n國立政治大學資訊科學系 教授\n科技部人工智慧普適研究中心研究員\n**專精領域：機器人學與認知計算**\n\n## 李蔡彥\n![劉吉軒](/assets/images/li.jpg)\n國立政治大學資訊科學系 教授\n科技部人工智慧普適研究中心研究員\n**專精領域：機器人學、電腦動畫**\n\n## 廖文宏\n![劉吉軒](/assets/images/whliao.jpg)\n國立政治大學資訊科學系 副教授\n科技部人工智慧普適研究中心研究員\n**​專精領域：多媒體信號處理、電腦視覺**\n\n## 紀明德\n![劉吉軒](/assets/images/mtchi.jpeg)\n國立政治大學資訊科學系 副教授\n科技部人工智慧普適研究中心研究員\n**專精領域：​圖學、資料視覺化**\n\n## 彭彥璁\n![劉吉軒](/assets/images/ytpeng.jpg)\n國立政治大學資訊科學系 助理教授\n科技部人工智慧普適研究中心研究員\n**專精領域：​影像辨識、影像還原**\n\n# 合作夥伴\n\n## Thunder Tiger - 雷虎科技股份有限公司\n![雷虎科技](/assets/images/TT-logo.jpg)\n\n## GEOSAT - 經緯航太科技 股份有限公司\n![經緯航太](/assets/images/Geosat-logo.png)\n\n## PAIR Labs - 交通大學人工智慧普適研究中心\n![交通大學人工智慧普適研究中心](/assets/images/PAIR-logo.png)\n\n## Aeroprobing - 翔探科技股份有限公司\n![翔探科技](/assets/images/Aeroprobing-logo.jpeg)\n","dir":"/about/","name":"1_members.md","path":"about/1_members.md","url":"/about/1_members.html"},{"layout":"default","title":"獲獎記錄","content":"# 獲獎記錄\n\n## 2020 民生公共物聯網資料應用競賽 - 佳作\n![HackIDB](/assets/images/IOT s.png)\n\n## 2020 通訊大賽之聯網未來挑戰賽 - 企業優秀獎\n![HackIDB](/assets/images/Mobile.png)\n\n## 2020 NVidia X HackIDB 智慧城市新創競賽 - 第三名\n![HackIDB](/assets/images/NVidia.jpg)\n\n## 2020 Intelligent Robocup FIRA AIR Autonomous Race- 第一名\n![FIRAAIR1](/assets/images/FIRA.png)\n\n## 2020 Intelligent Robocup FIRA AIR Emergency Services - 第三名\n![FIRAAIR2](/assets/images/FIRA2.png)\n\n## 2019 育秀盃 - 銀獎\n![育秀盃](/assets/images/YuXiu.png)\n\n### 得獎證明\n\n![育秀盃](/assets/images/AYuXiu.png)\n\n## 2019 中技社人工智慧創意競賽 - 第三名\n![中技社人工智慧創意競賽](/assets/images/ZhongJiShe.jpg)\n\n![中技社人工智慧創意競賽](/assets/images/AZhongJiShe.png)\n","dir":"/about/","name":"2_Awards.md","path":"about/2_Awards.md","url":"/about/2_Awards.html"},{"layout":"default","title":"學術發表","content":"# 學術發表\n\n## 2020 年發表之學術論文\n\n1. S. Huang, Y. Peng, C. Chang, K. Cheng, S. Huang and B. Chen, \"Restoration of Images With High-Density Impulsive Noise Based on Sparse Approximation and Ant-Colony Optimization,\" in IEEE Access, vol. 8, pp. 99180-99189, 2020, doi: 10.1109/ACCESS.2020.2995647.\n\n2. J. Yin, B. Chen, Y. Peng and C. Tsai, \"Deep Battery Saver: End-to-end Learning for Power Constrained Contrast Enhancement,\" in IEEE Transactions on Multimedia, doi: 10.1109/TMM.2020.2992962.\n\n3. J. Yin, B. Chen, Y. Peng and C. Tsai, \"Deep Prior Guided Network For High-Quality Image Fusion,\" 2020 IEEE International Conference on Multimedia and Expo (ICME), London, United Kingdom, 2020, pp. 1-6, doi: 10.1109/ICME46284.2020.9102832.\n\n4. Huang, Y. T., Lee, G. Y., Soong, R. T., & Liu, J. S., Real-Time Vision-Based River Detection and Lateral Shot Following for Autonomous UAVs. In International Conference on Real-time Computing and Robotics (RCAR). IEEE, August 2020.\n\n5. Huang, Y. T., Liao, W. H., & Huang, C. W., Defense mechanism against adversarial attacks using density-based representation of images Contrast Enhancement. In International Conference on Pattern Recognition (ICPR), IEEE,  Jan 2021.\n\n6. Liao, W. H. & Huang, Y. T., Investigation of DNN Model Robustness Using Heterogeneous Datasets. In International Conference on Pattern Recognition (ICPR), IEEE, Jan 2021.\n\n## 2019 年發表之學術論文\n\n1. Ru-Tai Soong, Gong-Yi Li, Yen-Ting Huang, and Jyi-Shane Liu, “Real-Time Autonomous UAV Task Navigation using Behavior Tree”, The 2019 IEEE/RSJ International Conference on Intelligent Robots and Systems, Behavior Tree in Robotic Systems Workshop (IROS), 2019.\n\n2. Y.-T. Peng, M.-H. Lin, C.-L. Tang and C.-H. Wu, “Image Denoising based on Overlapped and Adaptive Gaussian Smoothing and Convolutional Refinement Networks”, IEEE ISM 2019.\n\n3. Yen-Ting Huang, Yan-Tsung Peng, and Wen-Hung Liao, “Enhancing object detection in the dark using U-Net based restoration module”, The 16th IEEE International Conference on Advanced Video Signal-based Surveillance (AVSS), Taipei, Taiwan, September 2019.\n\n4. Yizhou Wang, Yen-Ting Huang, and Jenq-Neng Hwang, “Monocular Visual Object 3D Localization in Road Scenes”, The 27th ACM International Conference on Multimedia (ACMMM), Nice, France, October 2019.\n\n5. Gong-Yi Li, Ru-Tai Soong, Jyi-Shane Liu, and Yen-Ting Huang, “UAV System Integration of Real-time Sensing and Flight Task Control for Autonomous Building Inspection Task”, In Proceedings of the 24th International Conference on Technologies and Applications of Artificial Intelligence (TAAI), November 2019.\n\n6. Jyi-Shane and Gong-Yi Lee, “A Carrot in Probabilistic Grid Approach for Quadrotor Line Following on Vertical Surfaces”, The 2019 International Conference on Unmanned Aircraft Systems (ICUAS), June 2019.\n\n7. Wen-Hung Liao, Carolyn Yu, and Yi-Chieh Wu, “Construction and optimization of feature descriptor based on dynamic local intensity order relations of pixel group”, The 16th International Conference on Image Analysis and Recognition (ICIAR), August 2019.\n","dir":"/about/","name":"3_Publication.md","path":"about/3_Publication.md","url":"/about/3_Publication.html"},{"layout":"default","title":"介面模組","content":"# 介面模組\n\n## 基於 ROS 之無人機地面站\n\n```\nGround Control Station based on ROS#\n```\n\n![運動模組](/assets/images/interface.png)\n\n整合了 ROS 的 Topic 訂閱與發送，透過影像視覺、狀態回報、快捷指令、飛行路徑繪製等功能達成監控無人機任務之地面站；並可依據情況進行任務終止，空中系統重設（Aeriel Reset）、空中讀取狀態繼續任務（State Recover）、切入手動遙控模式。\n\n## 基於 AirSim 之系統整合環境模擬器\n\n```\nSystem Integration Simulator based on ROS and AirSim\n```\n\n![AirSim](/assets/images/airsim.png)\n\n將實體無人機系統整合的應用，轉換成能夠在 AirSim 模擬環境裡進行飛前演算和測試，降低實際飛行測試時的成本，更便於進行演算法的實驗；系統整合環境功能包括：ROS、Behavior Tree、Learning-based visual computing and computer vision、Task Environment Setup。\n\n## 強化學習之資料視覺化分析\n\n```\nData Visualization Analysis on Reinforcement Learning to understand and explain AI Learning Behavior\n```\n\n![強化學習之資料視覺化分析](/assets/images/dpdv.png)\n\n理解 AI 的學習行為，將 AI 所關注的重點與決策的依據透過視覺化的方式呈現使其更容易理解；圖為對最後一層 Hidden Layer 的 Feature map 做 T-sne 降維，根據選擇行為或分群結果以不同顏色視覺化，藉著對相同群的場景做疊加，觀察 AI 於場景歸納和決策。\n","dir":"/system/","name":"1-4_Interface.md","path":"system/1-4_Interface.md","url":"/system/1-4_Interface.html"},{"layout":"default","title":"核心技術模組","content":"# 核心技術模組\n\n核心技術模組：**認知、運動、感知、介面**\n\n![核心技術模組](/assets/images/Modules.png)\n\n## 認知模組\n![認知模組](/assets/images/buildinginspection.jpg)\n發展無人機環境認知與任務理解能力，建立智慧系統架構、知識模型與決策判斷機制；由於無人機本身有載重量、電源、反應時間等條件限制，實驗室中研發的人工智慧技術，未必能直接套用，必須以無人機的真實任務情境為基礎，開發出真正適用的認知計算技術，包括環境狀態認知及應變決策能力。\n\n更深入了解認知模組技術：[![認知模組](/System/1-1_Cognition.html)](/System/1-1_Cognition.html)\n\n## 運動模組\n![運動模組](/assets/images/motion.png)\n研發適用於無人機計算環境的人工智慧最佳化技術、機器人運動規劃技術、虛擬攝影機規劃技術，以解決無人機任務導向之自主飛行運動規畫問題，如：全面空拍地形輪廓追蹤及影像分析之最佳路徑規劃、特定物件檢視之即時避碰與路徑規劃等。\n\n更深入了解認知模組技術：[![運動模組](/System/1-1_Cognition.html)](/System/1-2_Motion.html)\n\n## 感知模組\n![感知模組](/assets/images/perception.jpg)\n以深度學習為基礎，針對多頻譜、多尺度、多視角之資訊來源，發展異質性與高維度海量影像高效能分析與辨識技術。進行高效率、合宜精準度之物件偵測與辨識，以因應不同類型與階段的應用，並支援機上辨識，著重於精簡資料維度的迅速辨識效能與即時反應，以提供環境感知與避障等所需資訊。\n\n更深入了解認知模組技術：[![感知模組](/System/1-1_Cognition.html)](/System/1-3_Perception.html)\n\n## 介面模組\n![介面模組](/assets/images/interface.png)\n建立人員監控無人機任務之視覺化呈現與互動介面模組，提供空間與任務狀態的視覺儀表板，讓操作人員能透過介面監控與下達指示。同時，也協助無人機的人工智慧預先模擬與驗證，並研發出能輔助研究人員理解人工智慧學習歷程的視覺化工具，藉由新工具增強研發的成果與產出。\n\n更深入了解認知模組技術：[![介面模組](/System/1-1_Cognition.html)](/System/1-4_Interface.html)\n","dir":"/system/","name":"1_Core.md","path":"system/1_Core.md","url":"/system/1_Core.html"},{"layout":"default","title":"自主智慧無人機系統","content":"# 自主智慧無人機系統\n\n## 系統目標\n\n我們專注於研發自主智慧無人機系統，透過結合視覺導航和決策模型，整合介面及雲端衛星資料庫，再藉由國內無人機廠商所研發之硬體設備作爲平臺，提供一套完整的客製化解決方案給客戶應用於不同的場景與任務。\n\n![雷虎科技](/assets/images/Architecture.png)\n\n## 目前成果與應用情境\n\n目前已\b\b開發之自主智慧無人機系統的應用情境有：\n\n- 河岸建築巡檢\n- 文件遞送\n- 立體建築掃描\n- 橋墩掃描\n- 柱狀物體掃描\n- 河川巡檢\n- 定點高空盤旋與降落\n\n## 108 年成果展示\n\n河岸建築巡檢、文件遞送、立體建築掃描及橋墩掃描任務：\n\n<iframe width=\"853\" height=\"480\" src=\"https://www.youtube.com/embed/xoiGH-rqt3Q\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n## 109 年成果展示\n\n河川巡檢與衛星圖資對應：\n\n<iframe width=\"853\" height=\"480\" src=\"https://www.youtube.com/embed/R08vfUiyqv4?list=PLC8CWoAsfoXWmzhyGN3_GSfdYHJycdCNg\" title=\"YouTube video player\" frameborder=\"0\" allow=\"accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture\" allowfullscreen></iframe>\n\n### 河川巡檢任務相關功能\n\n![河川巡檢與衛星圖資對應](/assets/images/Rivers.png)\n\n河川巡檢任務整合了河川視覺導航及物件定位等功能，能協助偵測出河川週遭的物件，並藉由空間定位技術和雲端衛星圖資的整合，在地圖上標記出物件位置，使巡檢人員無需親自巡邏，亦可透過地圖介面和影片截圖了解河川狀況。\n\n更多成果影片：[![連結](https://www.youtube.com/watch?v=UZ19rnpisYg&list=PLC8CWoAsfoXWmzhyGN3_GSfdYHJycdCNg)](https://www.youtube.com/watch?v=UZ19rnpisYg&list=PLC8CWoAsfoXWmzhyGN3_GSfdYHJycdCNg)\n","dir":"/system/","name":"0_Application.md","path":"system/0_Application.md","url":"/system/0_Application.html"},{"layout":"default","title":"認知模組","content":"# 認知模組\n\n## 任務導向之決策模型\n\n```\nMission-oriented Decision Making Model\n```\n\n![任務導向之決策模型](/assets/images/BT.png)\n\n使用行為樹（Behavior Tree）為框架，透過節點執行和切換不同子任務，並依需求動態啟用或關閉模組，使無人機能自動完成任務。\n\n## 空間資訊模型\n\n```\nSpace Information Model\n```\n\n![空間資訊模型](/assets/images/SLAM.png)\n\n使用無人機影像透過 SLAM 建立建築點雲模型，可搭配任務導向模型進行各種模型掃描或避障。\n\n## 精準立面線條跟隨\n\n```\nLine Detection and Following Model\n```\n\n![精準立面線條跟隨](/assets/images/LineFollowing.png)\n\n透過兩層方形 / 圓弧機率方格模型進行立面線條跟隨，並加入速度抑制等方式加強控制；經直線、折線、方形和曲線測試，具備高精準度及低線條偏出誤差。\n\n## 區域巡邏及特點掃描\n\n```\nUAV Patrol and Statistical Collection on Pedestrians and Vehicles\n```\n\n![區域巡邏及特點掃描](/assets/images/Patrol.png)\n\n搭配行為樹使其自動控制化減少人力上控制的需求，再藉由低成本微型無人機在指定區域自動巡邏，同時透過鏡頭使用深度學習模型來偵測物件，並透過電腦視覺和鏡頭參數計算出其定位，統計出其數量及物件在無人機視線範圍的移動軌跡。\n\n## 河川巡檢系統與圖資對應\n\n```\nRiver Inspection System and Mapping on Satellite Map\n```\n\n![河川巡檢系統與圖資對應](/assets/images/River.png)\n\n河川巡檢任務整合了河川視覺導航及物件定位等功能，能協助偵測出河川週遭的物件，並藉由空間定位技術和雲端衛星圖資的整合，在地圖上標記出物件位置，使巡檢人員無需親自巡邏，亦可透過地圖介面和影片截圖了解河川狀況。\n\n## 階層式手勢控制架構\n\n```\nHierarchical Gesture Control Architecture for UAV\n```\n\n![階層式手勢控制架構](/assets/images/Hand.png)\n\n無論是自主或半自主控制，由於操作人員對任務理解比系統更全面，但因距離的關係操作人員往往對無人機周遭環境在認知有誤差，若進行修正控制將耗費時間影響任務執行效率，因此好的遠程操作仍十分重要。\n\n本技術透過電腦視覺分析手和手指的各個節點，計算節點間的關係，藉以判斷每一隻手指當前的伸直與彎曲狀態，並且區分所屬的左右手，構建出階層式的手勢控制架構，讓使用者能透過不同層級的手勢下達不同層級的指令，藉此控制無人機執行較複雜的任務；同時，也加入視覺里程計(Visual Odometry)，獲取更多的空間資訊，以增強控制系統的情境意識。\n","dir":"/system/","name":"1-1_Cognition.md","path":"system/1-1_Cognition.md","url":"/system/1-1_Cognition.html"},{"layout":"default","title":"運動模組","content":"# 運動模組\n\n## 區域掃描之路徑規劃\n\n```\n2D Coverage Path Planning Algorithm\n```\n\n![運動模組](/assets/images/2DPathPlanning.png)\n\n給定一掃描之區域和相機參數，計算出該無人機飛經該區域鏡頭視角之覆蓋式掃描路徑，包含起飛點和一系列航點；完成掃描後會返回起飛點。\n\n### 區域路徑規劃例子 - 棒球場\n\n#### 政大河堤棒球場 - 無人機飛行高度：7m\n![棒球場](/assets/images/baseball.png)\n\n#### 監控畫面\n![監控畫面一](/assets/images/interface.png)\n\n### 區域路徑規劃例子 - 操場\n\n#### 政大操場掃描 - 無人機飛行高度：7m\n![操場](/assets/images/stadium.png)\n\n#### 監控畫面\n![監控畫面二](/assets/images/interface2.png)\n\n\n## 三維建築檢視 - 模型簡化\n\n```\n\nBuilding Inspection - 3D Model Simplification\n```\n\n![運動模組](/assets/images/Camera.png)\n\n根據無人機與建物的距離和無人機視角（field of view）​所張出的相機視野範圍（Camera footprint）對欲掃描模型進行模型簡化，以降低後續路徑之計算複雜度，簡化目標為使建物模型的每個面都大於或等於相機視野範圍。\n\n### 模型簡化 - 例子一\n![例子一](/assets/images/Example1.png)\n### 模型簡化 - 例子二\n![例子二](/assets/images/Example2.png)\n### 模型簡化 - 例子三\n![例子三](/assets/images/Example3.png)\n\n## 三維建築檢視 - 視點取樣\n\n```\nBuilding Inspection - Viewpoints Generation\n```\n\n![視點取樣](/assets/images/motion.png)\n\n使用簡化後的模型，整合無人機的相機參數，透過檢視距離與相機視野等資料進行檢視點（Viewpoints）取樣。\n\n## 三維建築檢視 - 路徑生成\n\n```\nBuilding Inspection - Coverage Path Planning\n```\n\n![3D 路徑規劃](/assets/images/3DPath.png)\n\n透過預先計算單面檢視路徑規劃，再整合可涵蓋所有建物表面之路徑；無人機對建物距離為 2m，鏡頭視角 Field of View 為 80 度。\n\n\n## ​機上協同式無人機路徑規劃演算法\n\n![機上協同式無人機路徑規劃演算法](/assets/images/multi.png)\n\n​目前無人機的動態路徑規劃都屬於由無人機上的傳感器(Sensor)蒐集資料，再傳輸回基地台(電腦)運算出全局的(Global)路徑規劃，並將路徑規劃指令傳給無人機做執行。\n","dir":"/system/","name":"1-2_Motion.md","path":"system/1-2_Motion.md","url":"/system/1-2_Motion.html"},{"layout":"default","title":"感知模組","content":"# 感知模組\n\n## 基於三維定位之避障\n\n```\nAvoidance based on 3D Localization\n```\n\n![基於三維定位之避障](/assets/images/GroundPlan.png)\n\n透過 YOLO V3 的物件辨識，利用相機參數和視覺資訊反推無人機所在位置，計算出與障礙物的距離、方向、位置，再使用 RRT-Star 演算法進行動態的路徑規劃，對無人機下達指令進行迴避動作。​\n\n## ​補強低光源影像以增強物件辨識\n\n```\nEnhancing Object Detection in Degraded Images\n```\n\n![補強低光源影像以增強物件辨識](/assets/images/perception.jpg)\n\n本技術利用卷積神經網路強大的學習能力，還原低亮度且非均勻光源下的影像，並以該神經網路作為前處理，強化現有物件辨識方法的準確度。本技術在真實的 VisDrone (無人機空拍資料集)上進行充分的評估，驗證該技術能增強物件辨識約 5 的召回率，同時本技術亦可被應用於過曝影像的還原。\n\n可廣泛應用於無人載具、監控或需要即時影像追蹤的應用情境，透過將無人載具即時取得的影像進行處理，能提高無人載具在即時運算時的物件辨識率。\n\n\n## 基於 RGB-D 影像的深度學習技巧在之避障\n\n```\nCollision Avoidance Based on RGB-D Images Using Deep Learning Techniques\n```\n\n\b本技術以 RGB-D 影像與深度學習為基礎，分別為沒有搭載深度攝影機的無人機和有搭載深度攝影機的無人機，提出自動避障的方法。\n\n![RGBD迴避障礙](/assets/images/RGBD01.png)\n\n對於沒有搭載深度攝影機的無人機，透過開放的碰撞資料集使用深度估計模型預測出對應的深度資訊，再透過深度資訊在 RGB 影像中分割出危險和安全等區域，並使用即時語義分割模型進行訓練，將從彩色影像中預測出來的區域分布，使無人機找到一個合適的避障方向。\n\n![RGBD迴避障礙2](/assets/images/RGBD2.jpg)\n\n對於搭載深度攝影機的無人機，本研究使用即時語義分割模型和分群演算法，得到物體的類別和位置資訊，接著使用路徑規劃演算法幫助無人機找出最佳的避障路徑。本研究所訓練的深度學習模型可以在嵌入式裝置上進行推論，因此我們提出的避障方法將可應用於運算資源有限的無人機。\n\n## ​河川多頻譜分係\n\n```\nDigital Multi-Spectral Video Analysis for River\n```\n\n![河川多頻譜](/assets/images/multispectrum.png)\n\n透過無人機的鏡頭及熱影像儀，取得 RGB 影像與熱影像，讓無人機在自動沿著河道飛行時，可透過異常偵測判斷河川水質是否有異常。上圖為已蒐集的 RGB 影像及熱成像，其中有標註河川範圍，並使用現有神經網路對河川資料集進行分割\n\n![河川多頻譜2](/assets/images/segmentation.png)\n\n### 相關研究實驗參數\n\n![資料集 - RGB 影像及熱影像](/assets/images/dataset.png)\n\n- Train/Val/Test: 200/50/50 images\n- Image Resize/Crop/Pad to 320*320\n- Feature Pyramid Network (FPN)\n- Encoder = se_resnext101_32x4d\n- Encoder_Weights = imagenet\n- Train 40 epoches\n","dir":"/system/","name":"1-3_Perception.md","path":"system/1-3_Perception.md","url":"/system/1-3_Perception.html"},{"sort":1,"permalink":"/about/","layout":"default","title":"實驗室簡介","content":"<h1 id=\"實驗室簡介\">實驗室簡介</h1>\n\n<ul>\n <li><a href=\"/about/0_starlab.html\">關於 Star Lab</a></li>\n <li><a href=\"/about/1_members.html\">團隊成員與合作夥伴</a></li>\n <li><a href=\"/about/2_Awards.html\">獲獎記錄</a></li>\n <li><a href=\"/about/3_Publication.html\">學術發表</a></li>\n</ul>\n","dir":"/about/","name":"README.md","path":"about/README.md","url":"/about/"},{"sort":2,"permalink":"/system/","layout":"default","title":"系統整合成果","content":"<h1 id=\"系統整合成果\">系統整合成果</h1>\n\n<ul>\n <li><a href=\"/system/1-4_Interface.html\">介面模組</a></li>\n <li><a href=\"/system/1_Core.html\">核心技術模組</a></li>\n <li><a href=\"/system/0_Application.html\">自主智慧無人機系統</a></li>\n <li><a href=\"/system/1-1_Cognition.html\">認知模組</a></li>\n <li><a href=\"/system/1-2_Motion.html\">運動模組</a></li>\n <li><a href=\"/system/1-3_Perception.html\">感知模組</a></li>\n</ul>\n","dir":"/system/","name":"README.md","path":"system/README.md","url":"/system/"}]